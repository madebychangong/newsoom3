#!/usr/bin/env python3
"""
ê°œì„ ëœ ì›ê³  ìë™ ìˆ˜ì • ì‹œìŠ¤í…œ v2
- í”„ë¡¬í”„íŠ¸ ê·¹ë‹¨ì  ë‹¨ìˆœí™”
- ìˆ«ì ê·œì¹™ ìš°ì„  ì ìš©
"""

import os
import re
import pandas as pd
from typing import Dict, List
from collections import Counter
import google.generativeai as genai


class AutoManuscriptRewriterV2:
    """ê°œì„ ëœ ì›ê³  ìë™ ê²€ìˆ˜ ë° ìˆ˜ì • ì‹œìŠ¤í…œ"""

    def __init__(self, forbidden_words_file='ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸.xlsx', gemini_api_key=None, model_choice=1):
        """ì´ˆê¸°í™”"""
        self.forbidden_words_file = forbidden_words_file
        self.load_forbidden_words()

        # Gemini API ì„¤ì •
        api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ gemini_api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")

        genai.configure(api_key=api_key)

        if model_choice == 2:
            model_name = 'gemini-2.0-flash-exp'
            print("ğŸš€ ëª¨ë¸: gemini-2.0-flash-exp")
        else:
            model_name = 'gemini-2.5-pro'
            print("ğŸ¯ ëª¨ë¸: gemini-2.5-pro")

        self.model = genai.GenerativeModel(model_name)

    def load_forbidden_words(self):
        """ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
        try:
            df = pd.read_excel(self.forbidden_words_file)
            self.forbidden_words = {}

            for idx, row in df.iterrows():
                forbidden = row.iloc[1]
                if pd.notna(forbidden) and forbidden != 'ê¸ˆì¹™ì–´':
                    alternatives = []
                    for i in range(2, len(row)):
                        if pd.notna(row.iloc[i]):
                            alternatives.append(str(row.iloc[i]))
                    if alternatives:
                        self.forbidden_words[str(forbidden)] = alternatives

            print(f"âœ… ê¸ˆì¹™ì–´ {len(self.forbidden_words)}ê°œ ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ ê¸ˆì¹™ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.forbidden_words = {}

    def get_first_paragraph(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì¶”ì¶œ"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return paragraphs[0].strip() if paragraphs else ""

    def get_rest_paragraphs(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì œì™¸í•œ ë‚˜ë¨¸ì§€"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return '\n\n'.join(paragraphs[1:]).strip() if len(paragraphs) > 1 else ""

    def count_keyword(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œ ì¹´ìš´íŒ… (ë„ì–´ì“°ê¸° ê¸°ì¤€)"""
        if not keyword or pd.isna(keyword):
            return 0
        pattern = rf'{re.escape(keyword)}(?=\s|[^\wê°€-í£]|$)'
        return len(re.findall(pattern, text))

    def count_sentences_starting_with(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ê°œìˆ˜"""
        if not keyword:
            return 0

        sentences = []
        for line in text.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                parts = re.split(r'([.!?])\s*', line)
                current = ""
                for i, part in enumerate(parts):
                    if part in '.!?':
                        current += part
                        if current.strip():
                            sentences.append(current.strip())
                        current = ""
                    else:
                        current += part
                if current.strip():
                    sentences.append(current.strip())

        count = 0
        for sentence in sentences:
            if sentence.startswith(keyword):
                count += 1

        return count

    def count_sentences_between_keywords(self, paragraph: str, keyword: str) -> int:
        """ì²« ë¬¸ë‹¨ì—ì„œ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥ ê°œìˆ˜"""
        if not keyword or not paragraph:
            return 0

        text = '\n'.join([line for line in paragraph.split('\n') if not line.strip().startswith('#')])
        sentences = re.split(r'[.,]\s*', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        keyword_pattern = rf'{re.escape(keyword)}(?=\s|[^\wê°€-í£]|$)'

        keyword_indices = []
        for i, sentence in enumerate(sentences):
            if re.search(keyword_pattern, sentence):
                keyword_indices.append(i)

        if len(keyword_indices) >= 2:
            return keyword_indices[1] - keyword_indices[0] - 1

        return 0

    def count_subkeywords(self, text: str, exclude_keywords: List[str] = None) -> int:
        """ì„œë¸Œí‚¤ì›Œë“œ ëª©ë¡ ìˆ˜ (í•œê¸€ ë‹¨ì–´ + íŠ¹ìˆ˜ë¬¸ì ë°˜ë³µ)"""
        if exclude_keywords is None:
            exclude_keywords = []

        words = re.findall(r'[ê°€-í£]+', text)
        # ì•ë’¤ ë„ì–´ì“°ê¸°ê°€ ìˆëŠ” íŠ¹ìˆ˜ë¬¸ì 2ê°œ ì´ìƒ ë°˜ë³µ (^^, ;;, .., ..., ë“±)
        # íŒ¨í„´ ì „ì²´ë¥¼ ì¡ìŒ: .. ì™€ ... ëŠ” ë³„ê°œì˜ ì„œë¸Œí‚¤ì›Œë“œ
        special_patterns = re.findall(r'(?<=\s)(([^\w\sê°€-í£])\2+)(?=\s)', text)
        punct_patterns = [match[0] for match in special_patterns]

        word_counter = Counter(words)
        punct_counter = Counter(punct_patterns)

        subkeywords = set()
        for word, count in word_counter.items():
            if count >= 2 and len(word) >= 2 and word not in exclude_keywords:
                subkeywords.add(word)

        # íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´: 2íšŒ ì´ìƒ ë“±ì¥í•˜ë©´ ì„œë¸Œí‚¤ì›Œë“œë¡œ ì¹´ìš´íŠ¸
        # ì˜ˆ: '..' 2íšŒ, '...' 2íšŒ â†’ ì„œë¸Œí‚¤ì›Œë“œ 2ê°œ (ë³„ê°œ!)
        for pattern, count in punct_counter.items():
            if count >= 2:
                subkeywords.add(pattern)

        return len(subkeywords)

    def parse_target_value(self, value_str) -> Dict[str, int]:
        """D, Eì—´ ëª©í‘œê°’ íŒŒì‹±"""
        if pd.isna(value_str) or value_str == '-':
            return {}

        result = {}
        lines = str(value_str).split('\n')
        for line in lines:
            if ':' in line:
                parts = line.split(':')
                kw = parts[0].strip()
                count = int(parts[1].strip())
                result[kw] = count
        return result

    def replace_forbidden_words(self, text: str, keyword: str = None, target_pieces_str: str = None) -> str:
        """ê¸ˆì¹™ì–´ ì¹˜í™˜ (ë‹¨, í†µí‚¤ì›Œë“œ/ì¡°ê°í‚¤ì›Œë“œ ì•ˆì˜ ê¸ˆì¹™ì–´ëŠ” ë³´í˜¸)"""

        # ë³´í˜¸í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        protected_keywords = []
        if keyword:
            protected_keywords.append(keyword)
        if target_pieces_str:
            target_pieces = self.parse_target_value(target_pieces_str)
            protected_keywords.extend(target_pieces.keys())

        # ì¼ë°˜ ê¸ˆì¹™ì–´ ì¹˜í™˜ (ë³´í˜¸ ëŒ€ìƒ ì œì™¸)
        for forbidden, alternatives in self.forbidden_words.items():
            if not alternatives:
                continue

            # ì´ ê¸ˆì¹™ì–´ê°€ ë³´í˜¸ ëŒ€ìƒ í‚¤ì›Œë“œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            is_protected = any(forbidden in pk for pk in protected_keywords)

            if not is_protected:
                # ë³´í˜¸ ëŒ€ìƒì´ ì•„ë‹ˆë©´ ì¹˜í™˜
                text = text.replace(forbidden, alternatives[0])

        # íŠ¹ìˆ˜ ê¸ˆì¹™ì–´ ë³€í™˜ (ë³´í˜¸ ëŒ€ìƒì´ì–´ë„ í•­ìƒ ë³€í™˜)
        text = text.replace("ë„¤ìš”", "ë‚´ìš”")
        text = text.replace("í•˜ë”ë¼", "í•˜ë” ë¼")

        return text

    def analyze_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int) -> Dict:
        """ì›ê³  ë¶„ì„"""
        text_no_title = '\n'.join([line for line in manuscript.split('\n')
                                   if not line.strip().startswith('#')])

        ì²«ë¬¸ë‹¨ = self.get_first_paragraph(manuscript)
        ë‚˜ë¨¸ì§€ = self.get_rest_paragraphs(manuscript)

        target_whole = self.parse_target_value(target_whole_str)
        target_pieces = self.parse_target_value(target_pieces_str)

        actual_chars = len(text_no_title.replace(' ', '').replace('\n', ''))
        ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ = self.count_keyword(ì²«ë¬¸ë‹¨, keyword)
        ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘ = self.count_sentences_starting_with(text_no_title, keyword)
        ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜ = self.count_sentences_between_keywords(ì²«ë¬¸ë‹¨, keyword)

        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ = {}
        for kw, target in target_whole.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual}

        ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ = {}
        for kw, target in target_pieces.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual}

        exclude_list = [keyword] if keyword else []
        if target_pieces:
            exclude_list.extend(target_pieces.keys())
        actual_subkeywords = self.count_subkeywords(text_no_title, exclude_list)

        return {
            'chars': actual_chars,
            'chars_in_range': 300 <= actual_chars <= 900,
            'ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ': ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ,
            'í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘': ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘,
            'ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜': ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜,
            'ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ,
            'ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ,
            'subkeywords': {'target': target_subkeywords, 'actual': actual_subkeywords}
        }

    def create_simple_prompt(self, manuscript: str, keyword: str, analysis: Dict,
                            target_whole_str: str, target_pieces_str: str) -> str:
        """ê·¹ë‹¨ì ìœ¼ë¡œ ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸ (ìˆ«ì ê·œì¹™ë§Œ ê°•ì¡°)"""

        # í•„ìš”í•œ ìˆ˜ì •ì‚¬í•­ë§Œ ì¶”ì¶œ
        tasks = []

        # 1. ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ (ì •í™•íˆ 2ê°œ)
        ì²«ë¬¸ë‹¨_count = analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']
        if ì²«ë¬¸ë‹¨_count != 2:
            if ì²«ë¬¸ë‹¨_count < 2:
                tasks.append(f"ì²« ë¬¸ë‹¨ì— [{keyword}] ë¥¼ {2 - ì²«ë¬¸ë‹¨_count}ê°œ ë” ì¶”ê°€í•˜ì„¸ìš”. (í˜„ì¬ {ì²«ë¬¸ë‹¨_count}ê°œ â†’ ëª©í‘œ ì •í™•íˆ 2ê°œ)")
            else:
                tasks.append(f"ì²« ë¬¸ë‹¨ì— [{keyword}] ë¥¼ {ì²«ë¬¸ë‹¨_count - 2}ê°œ ì œê±°í•˜ì„¸ìš”. (í˜„ì¬ {ì²«ë¬¸ë‹¨_count}ê°œ â†’ ëª©í‘œ ì •í™•íˆ 2ê°œ)")

        # 2. ë¬¸ì¥ ì‹œì‘ (ì •í™•íˆ 2ê°œ)
        ë¬¸ì¥ì‹œì‘_count = analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']
        if ë¬¸ì¥ì‹œì‘_count != 2:
            if ë¬¸ì¥ì‹œì‘_count < 2:
                tasks.append(f"ì¤„ ë§¨ ì•ì—ì„œ [{keyword}]ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì„ {2 - ë¬¸ì¥ì‹œì‘_count}ê°œ ë” ë§Œë“œì„¸ìš”. (í˜„ì¬ {ë¬¸ì¥ì‹œì‘_count}ê°œ â†’ ëª©í‘œ ì •í™•íˆ 2ê°œ)")
            else:
                tasks.append(f"ì¤„ ë§¨ ì•ì—ì„œ [{keyword}]ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì„ {ë¬¸ì¥ì‹œì‘_count - 2}ê°œ ì¤„ì´ì„¸ìš”. (í˜„ì¬ {ë¬¸ì¥ì‹œì‘_count}ê°œ â†’ ëª©í‘œ ì •í™•íˆ 2ê°œ)")

        # 3. ì²«ë¬¸ë‹¨ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥ (ìµœì†Œ 2ê°œ)
        í‚¤ì›Œë“œì‚¬ì´ = analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜']
        if í‚¤ì›Œë“œì‚¬ì´ < 2:
            tasks.append(f"ì²« ë¬¸ë‹¨ì—ì„œ ì²« ë²ˆì§¸ [{keyword}]ì™€ ë‘ ë²ˆì§¸ [{keyword}] ì‚¬ì´ì— ë¬¸ì¥ì„ {2 - í‚¤ì›Œë“œì‚¬ì´}ê°œ ë” ì¶”ê°€í•˜ì„¸ìš”. (í˜„ì¬ {í‚¤ì›Œë“œì‚¬ì´}ê°œ â†’ ëª©í‘œ ìµœì†Œ 2ê°œ)")

        # 4. ê¸€ììˆ˜
        chars = analysis['chars']
        if chars < 300:
            tasks.append(f"ê¸€ììˆ˜ë¥¼ {300 - chars}ì ì´ìƒ ëŠ˜ë¦¬ì„¸ìš”. (í˜„ì¬ {chars}ì â†’ ëª©í‘œ 300~900ì)")
        elif chars > 900:
            tasks.append(f"ê¸€ììˆ˜ë¥¼ {chars - 900}ì ì¤„ì´ì„¸ìš”. (í˜„ì¬ {chars}ì â†’ ëª©í‘œ 300~900ì)")

        # 5. ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ (ëª©í‘œ~ëª©í‘œ+1ê°œ í—ˆìš©, ê·¸ ì´ìƒ ì´ˆê³¼ ê¸ˆì§€)
        for kw, data in analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
            if data['actual'] < data['target']:
                diff = data['target'] - data['actual']
                tasks.append(f"ì²« ë¬¸ë‹¨ ì´í›„ì— [{kw}] ë¥¼ {diff}ê°œ ì¶”ê°€í•˜ì„¸ìš”. (í˜„ì¬ {data['actual']}ê°œ â†’ ëª©í‘œ {data['target']}~{data['target']+1}ê°œ)")
            elif data['actual'] > data['target'] + 1:
                diff = data['actual'] - data['target'] - 1
                tasks.append(f"ì²« ë¬¸ë‹¨ ì´í›„ì— [{kw}] ë¥¼ {diff}ê°œ ì œê±°í•˜ì„¸ìš”. (í˜„ì¬ {data['actual']}ê°œ â†’ ëª©í‘œ {data['target']}~{data['target']+1}ê°œ, ì´ˆê³¼ ê¸ˆì§€)")

        # 6. ì¡°ê°í‚¤ì›Œë“œ (ëª©í‘œ~ëª©í‘œ+1ê°œ í—ˆìš©, ê·¸ ì´ìƒ ì´ˆê³¼ ê¸ˆì§€)
        for kw, data in analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
            if data['actual'] < data['target']:
                diff = data['target'] - data['actual']
                tasks.append(f"ì²« ë¬¸ë‹¨ ì´í›„ì— [{kw}] ë¥¼ {diff}ê°œ ì¶”ê°€í•˜ì„¸ìš”. (í˜„ì¬ {data['actual']}ê°œ â†’ ëª©í‘œ {data['target']}~{data['target']+1}ê°œ)")
            elif data['actual'] > data['target'] + 1:
                diff = data['actual'] - data['target'] - 1
                tasks.append(f"ì²« ë¬¸ë‹¨ ì´í›„ì— [{kw}] ë¥¼ {diff}ê°œ ì œê±°í•˜ì„¸ìš”. (í˜„ì¬ {data['actual']}ê°œ â†’ ëª©í‘œ {data['target']}~{data['target']+1}ê°œ, ì´ˆê³¼ ê¸ˆì§€)")

        # 7. ì„œë¸Œí‚¤ì›Œë“œ (ëª©í‘œ~ëª©í‘œ+1ê°œ í—ˆìš©, ê·¸ ì´ìƒ ì´ˆê³¼ ê¸ˆì§€)
        sub_diff = analysis['subkeywords']['target'] - analysis['subkeywords']['actual']
        if sub_diff > 0:
            tasks.append(f"""ì„œë¸Œí‚¤ì›Œë“œë¥¼ {sub_diff}ê°œ ë” ì¶”ê°€í•˜ì„¸ìš”. (í˜„ì¬ {analysis['subkeywords']['actual']}ê°œ â†’ ëª©í‘œ {analysis['subkeywords']['target']}~{analysis['subkeywords']['target']+1}ê°œ)
   ë°©ë²• 1: 2íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” í•œê¸€ ë‹¨ì–´ ì¶”ê°€ (ì˜ˆ: "ì •ë§", "ë§ì´" ë“±)
   ë°©ë²• 2: íŠ¹ìˆ˜ë¬¸ì ë°˜ë³µ ì¶”ê°€ - ë¬¸ì¥ ëì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…
      ì˜ˆ: "ë„ì›€ì´ ëìœ¼ë©´ ì¢‹ê² ì–´ìš” ^^" (ë„ì–´ì“°ê¸° í•„ìˆ˜!)
      ì˜ˆ: "ê¶ê¸ˆí•œ ì ì´ ë§ë„¤ìš” .." (ë„ì–´ì“°ê¸° í•„ìˆ˜!)
      ì˜ˆ: "ì •ë§ ì¢‹ì•„ìš” ..." (ë„ì–´ì“°ê¸° í•„ìˆ˜!)
   âš ï¸ ì¤‘ìš”: ".." ì™€ "..." ëŠ” ë³„ê°œì˜ ì„œë¸Œí‚¤ì›Œë“œ! ê°ê° 2íšŒì”© ì‚¬ìš©í•´ì•¼ í•¨
   âš ï¸ íŠ¹ìˆ˜ë¬¸ìëŠ” ë°˜ë“œì‹œ ì•ë’¤ë¡œ ë„ì–´ì“°ê¸°!""")
        elif analysis['subkeywords']['actual'] > analysis['subkeywords']['target'] + 1:
            sub_excess = analysis['subkeywords']['actual'] - analysis['subkeywords']['target'] - 1
            tasks.append(f"ë°˜ë³µ ë‹¨ì–´ë¥¼ {sub_excess}ê°œ ì œê±°í•˜ì„¸ìš”. (í˜„ì¬ {analysis['subkeywords']['actual']}ê°œ â†’ ëª©í‘œ {analysis['subkeywords']['target']}~{analysis['subkeywords']['target']+1}ê°œ, ì´ˆê³¼ ê¸ˆì§€)")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë¸”ë¡œê·¸ ì›ê³ ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

ã€ìµœìš°ì„  ê·œì¹™ã€‘
1. í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ ë„ì–´ì“°ê¸°ë¡œ ë¶„ë¦¬: [{keyword} ] (ê³µë°± í•„ìˆ˜!)
   âŒ ë‚˜ìœ ì˜ˆ: {keyword}ë¥¼, {keyword}ì—
   âœ… ì¢‹ì€ ì˜ˆ: {keyword} ê´€ë ¨, {keyword} ì •ë³´

2. ì•„ë˜ ì‘ì—…ì„ ì •í™•í•œ ê°œìˆ˜ë¡œ ìˆ˜í–‰:

"""

        if tasks:
            for i, task in enumerate(tasks, 1):
                prompt += f"   {i}. {task}\n"
        else:
            prompt += "   âœ… ëª¨ë“  ê·œì¹™ì´ ì´ë¯¸ ì¶©ì¡±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì›ê³ ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n"

        prompt += f"""
ã€ì›ë³¸ ì›ê³ ã€‘
{manuscript}

ã€ì¶œë ¥ ê·œì¹™ã€‘
- ìˆ˜ì •ëœ ì›ê³ ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)
- ì œëª©(# ì‹œì‘)ì€ ì œê±°í•˜ì§€ ë§ ê²ƒ
- ìœ„ ì‘ì—…ì„ ëª¨ë‘ ì •í™•íˆ ìˆ˜í–‰í–ˆëŠ”ì§€ í™•ì¸ í›„ ì¶œë ¥
"""

        return prompt

    def rewrite_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int, max_retries: int = 3) -> Dict:
        """ì›ê³  ìë™ ìˆ˜ì • (ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„)"""

        for attempt in range(1, max_retries + 1):
            print(f"\n{'=' * 100}")
            print(f"{'ğŸ”„ ì¬ì‹œë„ ' + str(attempt) if attempt > 1 else 'ğŸ¤– 1ì°¨ ì‹œë„'}")
            print(f"{'=' * 100}")

            # ë¶„ì„
            analysis = self.analyze_manuscript(manuscript, keyword, target_whole_str,
                                              target_pieces_str, target_subkeywords)

            print(f"í˜„ì¬ ìƒíƒœ:")
            print(f"  - ê¸€ììˆ˜: {analysis['chars']}ì")
            print(f"  - ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ (ëª©í‘œ: 2íšŒ)")
            print(f"  - ë¬¸ì¥ ì‹œì‘: {analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ (ëª©í‘œ: 2ê°œ)")
            print(f"  - í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥: {analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜']}ê°œ (ëª©í‘œ: 2ê°œ ì´ìƒ)")

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_simple_prompt(manuscript, keyword, analysis,
                                              target_whole_str, target_pieces_str)

            try:
                # Geminië¡œ ìˆ˜ì •
                response = self.model.generate_content(prompt)
                rewritten = response.text.strip()

                # ìˆ˜ì • í›„ ì¬ë¶„ì„
                after_analysis = self.analyze_manuscript(rewritten, keyword, target_whole_str,
                                                        target_pieces_str, target_subkeywords)

                # ê²€ì¦ (ëª©í‘œ~ëª©í‘œ+1 ë²”ìœ„ í—ˆìš©, ì´ˆê³¼ ê¸ˆì§€!)
                all_ok = (
                    after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ'] == 2 and
                    after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘'] == 2 and
                    after_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜'] >= 2 and
                    after_analysis['chars_in_range'] and
                    all(d['target'] <= d['actual'] <= d['target'] + 1 for d in after_analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].values()) and
                    all(d['target'] <= d['actual'] <= d['target'] + 1 for d in after_analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].values()) and
                    after_analysis['subkeywords']['target'] <= after_analysis['subkeywords']['actual'] <= after_analysis['subkeywords']['target'] + 1
                )

                print(f"\nê²€ì¦ ê²°ê³¼:")
                print(f"  - ê¸€ììˆ˜: {after_analysis['chars']}ì {'âœ…' if after_analysis['chars_in_range'] else 'âŒ'}")
                print(f"  - ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ {'âœ…' if after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ'] == 2 else 'âŒ'}")
                print(f"  - ë¬¸ì¥ ì‹œì‘: {after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ {'âœ…' if after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘'] == 2 else 'âŒ'}")
                print(f"  - í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥: {after_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜']}ê°œ {'âœ…' if after_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜'] >= 2 else 'âŒ'}")

                if all_ok:
                    print(f"\nâœ… ì„±ê³µ! (ì‹œë„ {attempt}íšŒ)")
                    # ë§ˆì§€ë§‰ì— ê¸ˆì¹™ì–´ ì¹˜í™˜ (í†µí‚¤ì›Œë“œ/ì¡°ê°í‚¤ì›Œë“œëŠ” ë³´í˜¸)
                    final_output = self.replace_forbidden_words(rewritten, keyword, target_pieces_str)
                    return {
                        'success': True,
                        'original': manuscript,
                        'rewritten': final_output,
                        'before_analysis': analysis,
                        'after_analysis': after_analysis,
                        'attempts': attempt
                    }
                else:
                    print(f"\nâš ï¸ ê¸°ì¤€ ë¯¸ë‹¬ (ì‹œë„ {attempt}/{max_retries})")
                    manuscript = rewritten  # ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•´ í˜„ì¬ ê²°ê³¼ ì‚¬ìš©

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
                continue

        # ìµœì¢… ì‹¤íŒ¨ - ê·¸ë˜ë„ ê¸ˆì¹™ì–´ëŠ” ì¹˜í™˜ (í†µí‚¤ì›Œë“œ/ì¡°ê°í‚¤ì›Œë“œëŠ” ë³´í˜¸)
        final_rewritten = rewritten if 'rewritten' in locals() else manuscript
        final_output = self.replace_forbidden_words(final_rewritten, keyword, target_pieces_str)
        return {
            'success': False,
            'error': f'{max_retries}íšŒ ì‹œë„ í›„ì—ë„ ê¸°ì¤€ ë¯¸ë‹¬',
            'original': manuscript,
            'rewritten': final_output,
            'before_analysis': analysis,
            'after_analysis': after_analysis if 'after_analysis' in locals() else analysis,
            'attempts': max_retries
        }
