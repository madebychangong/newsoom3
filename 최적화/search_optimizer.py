"""
ë¸”ë¡œê·¸ ì›ê³  í‚¤ì›Œë“œ ë„ì–´ì“°ê¸° ìµœì í™” (í…œí”Œë¦¿ íŒ¨í„´ ê¸°ë°˜)
- ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™”
- í‚¤ì›Œë“œ+ì¡°ì‚¬ ì œê±°
- í‚¤ì›Œë“œ ì¶œí˜„ 2-3íšŒë¡œ ê°ì†Œ
- AI ì¬êµ¬ì„± (ì„ íƒ)
"""

import re
import random
import os
from typing import Dict, List, Optional
import pandas as pd
from blog_optimizer import BlogOptimizer


class SearchOptimizer(BlogOptimizer):
    """ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™” (í‚¤ì›Œë“œ ë„ì–´ì“°ê¸° + í‚¤ì›Œë“œ ê°ì†Œ)"""

    def __init__(self, forbidden_words_file='ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸.xlsx', use_ai=False, gemini_api_key=None):
        """
        ì´ˆê¸°í™”

        Args:
            forbidden_words_file: ê¸ˆì¹™ì–´ íŒŒì¼ ê²½ë¡œ
            use_ai: AI ì¬êµ¬ì„± ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: False)
            gemini_api_key: Gemini API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEY ì‚¬ìš©)
        """
        super().__init__(forbidden_words_file)
        self.use_ai = use_ai
        self.ai_rewriter = None

        # AI ì¬êµ¬ì„± í™œì„±í™”
        if self.use_ai:
            try:
                from ai_rewriter import AIRewriter
                self.ai_rewriter = AIRewriter(api_key=gemini_api_key)
                print("âœ… AI ì¬êµ¬ì„± ëª¨ë“œ í™œì„±í™”")
            except Exception as e:
                print(f"âš ï¸ AI ì¬êµ¬ì„± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("   í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ gemini_api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")
                self.use_ai = False

    def remove_hashtag_title(self, text: str) -> str:
        """# ì œëª© ì‚­ì œ"""
        lines = text.split('\n')
        if lines and lines[0].strip().startswith('#'):
            return '\n'.join(lines[1:]).strip()
        return text

    def remove_keyword_particles(self, text: str, keyword: str) -> str:
        """
        í‚¤ì›Œë“œ+ì¡°ì‚¬ ì œê±° ë˜ëŠ” ìˆ˜ì •

        ì „ëµ:
        1. í‚¤ì›Œë“œ+ë¥¼/ì„ â†’ í‚¤ì›Œë“œ + ë™ì‚¬ ë˜ëŠ” ì œê±°
        2. í‚¤ì›Œë“œ+ê°€/ì´ â†’ í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸ì¥ ì¬êµ¬ì„±
        3. í‚¤ì›Œë“œ+ì— â†’ í‚¤ì›Œë“œ ê´€í•´ì„œ ë˜ëŠ” ì œê±°
        4. í‚¤ì›Œë“œ+ë¼ëŠ” â†’ í‚¤ì›Œë“œ ë¼ëŠ” (ë„ì–´ì“°ê¸°)
        """
        if not keyword or pd.isna(keyword):
            return text

        modified = text

        # 1. í‚¤ì›Œë“œ+ë¥¼/ì„ ì²˜ë¦¬
        # "í‚¤ì›Œë“œë¥¼ ë¨¹ê³ " â†’ "í‚¤ì›Œë“œ ë¨¹ê³ "
        # "í‚¤ì›Œë“œë¥¼ ìµœê·¼ì—" â†’ "í‚¤ì›Œë“œ ë¼ëŠ” ê±¸ ìµœê·¼ì—"
        pattern1 = f'({re.escape(keyword)})[ë¥¼ì„]\\s+'
        modified = re.sub(pattern1, f'{keyword} ', modified)

        # 2. í‚¤ì›Œë“œ+ê°€/ì´ ì²˜ë¦¬
        # "í‚¤ì›Œë“œê°€ ì¢‹ë‹¤" â†’ "í‚¤ì›Œë“œ ì¢‹ë‹¤" ë˜ëŠ” "í‚¤ì›Œë“œ ë¨¹ìœ¼ë©´"
        pattern2 = f'({re.escape(keyword)})[ê°€ì´]\\s+'

        def replace_subject(match):
            # ëœë¤í•˜ê²Œ ì œê±° ë˜ëŠ” ëŒ€ì²´
            choices = [
                f'{keyword} ',
                f'{keyword} ë¨¹ìœ¼ë©´ ',
                f'{keyword} ì‚¬ìš©í•˜ë©´ ',
            ]
            return random.choice(choices)

        modified = re.sub(pattern2, replace_subject, modified)

        # 3. í‚¤ì›Œë“œ+ì— ì²˜ë¦¬
        # "í‚¤ì›Œë“œì— ëŒ€í•´" â†’ ë¬¸ì¥ ì‚­ì œ ë˜ëŠ” "í‚¤ì›Œë“œ ê´€í•´ì„œ"
        pattern3 = f'({re.escape(keyword)})ì—\\s+ëŒ€í•´'
        modified = re.sub(pattern3, '', modified)  # ì œëª©ì´ë¯€ë¡œ ì‚­ì œ

        pattern3b = f'({re.escape(keyword)})ì—\\s+'
        modified = re.sub(pattern3b, f'{keyword} ê´€í•´ì„œ ', modified)

        # 4. í‚¤ì›Œë“œ+ì˜ ì²˜ë¦¬
        pattern4 = f'({re.escape(keyword)})ì˜\\s+'
        modified = re.sub(pattern4, f'{keyword} ê´€ë ¨ ', modified)

        # 5. í‚¤ì›Œë“œ+ë¼ëŠ” â†’ í‚¤ì›Œë“œ ë¼ëŠ” (ë„ì–´ì“°ê¸°)
        pattern5 = f'({re.escape(keyword)})ë¼ëŠ”'
        modified = re.sub(pattern5, f'{keyword} ë¼ëŠ”', modified)

        # 6. í‚¤ì›Œë“œ+ëŠ”/ì€ ì¼ë¶€ ì œê±°
        # ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ë¶€ë§Œ ì œê±°
        pattern6 = f'({re.escape(keyword)})[ëŠ”ì€]\\s+'
        count = len(re.findall(pattern6, modified))
        if count > 1:
            # ì²« ë²ˆì§¸ë§Œ ì œê±°
            modified = re.sub(pattern6, f'{keyword} ', modified, count=1)

        return modified

    def reduce_keyword_frequency(self, text: str, keyword: str, target_count: int = 2) -> str:
        """
        í‚¤ì›Œë“œ ì¶œí˜„ íšŸìˆ˜ ì¤„ì´ê¸°

        5-6íšŒ â†’ 2-3íšŒë¡œ ê°ì†Œ
        """
        if not keyword or pd.isna(keyword):
            return text

        current_count = text.count(keyword)

        if current_count <= target_count:
            return text

        # ì´ˆê³¼ëœ í‚¤ì›Œë“œë¥¼ ëŒ€ëª…ì‚¬ë‚˜ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ êµì²´
        remove_count = current_count - target_count

        # í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì„œ ì¼ë¶€ë§Œ ì œê±°
        lines = text.split('\n')
        removed = 0

        for i, line in enumerate(lines):
            if removed >= remove_count:
                break

            if keyword in line:
                # ì´ ì¤„ì˜ í‚¤ì›Œë“œë¥¼ ëŒ€ëª…ì‚¬ë¡œ êµì²´
                line_keyword_count = line.count(keyword)

                # êµì²´í•  íšŸìˆ˜ ê³„ì‚°
                to_replace = min(line_keyword_count - 1, remove_count - removed) if line_keyword_count > 1 else (1 if removed < remove_count and i > 0 else 0)

                if to_replace > 0:
                    # í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°
                    import re
                    positions = [m.start() for m in re.finditer(re.escape(keyword), line)]

                    # ë’¤ì—ì„œë¶€í„° êµì²´ (ì•ìª½ í‚¤ì›Œë“œëŠ” ìœ ì§€)
                    new_line = line
                    replaced_count = 0

                    for pos in reversed(positions[1:] if line_keyword_count > 1 else positions):
                        if replaced_count >= to_replace:
                            break

                        # í‚¤ì›Œë“œ ë’¤ì— ë­ê°€ ìˆëŠ”ì§€ í™•ì¸
                        after_keyword = new_line[pos + len(keyword):pos + len(keyword) + 5] if pos + len(keyword) < len(new_line) else ""

                        # "í‚¤ì›Œë“œ ë¼ëŠ”" â†’ ê·¸ëƒ¥ ì œê±° (ë¼ëŠ” ìœ ì§€)
                        if after_keyword.startswith(' ë¼ëŠ”'):
                            # í‚¤ì›Œë“œë§Œ ì œê±°, ê³µë°±ê³¼ 'ë¼ëŠ”'ì€ ìœ ì§€í•˜ë˜ ìì—°ìŠ¤ëŸ½ê²Œ
                            new_line = new_line[:pos] + 'ì´ëŸ° ê±°' + new_line[pos + len(keyword):]
                        # "í‚¤ì›Œë“œë¥¼/ê°€/ëŠ”" ë“± ì¡°ì‚¬ â†’ ì´ë¯¸ 2ë‹¨ê³„ì—ì„œ ì²˜ë¦¬ëì–´ì•¼ í•˜ë¯€ë¡œ ë‹¨ìˆœ ì œê±°
                        elif after_keyword and after_keyword[0] in ['ë¥¼', 'ì„', 'ê°€', 'ì´', 'ëŠ”', 'ì€', 'ì—', 'ì˜']:
                            new_line = new_line[:pos] + 'ì´ê±°' + new_line[pos + len(keyword):]
                        else:
                            # ì¼ë°˜ì ì¸ ê²½ìš° "ì´ê±°"ë¡œ êµì²´
                            new_line = new_line[:pos] + 'ì´ê±°' + new_line[pos + len(keyword):]

                        replaced_count += 1

                    lines[i] = new_line
                    removed += replaced_count

        return '\n'.join(lines)

    def optimize_for_search(self, text: str, keyword: str, brand: str = '') -> Dict:
        """
        ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™”

        ì‘ì—… ìˆœì„œ:
        1. # ì œëª© ì‚­ì œ
        2. í‚¤ì›Œë“œ+ì¡°ì‚¬ ì œê±°
        3. í‚¤ì›Œë“œ ì¶œí˜„ ê°ì†Œ (2-3íšŒ)
        4. ê¸ˆì¹™ì–´ ì¹˜í™˜
        5. AI í‘œí˜„ ì œê±°
        6. AI ì¬êµ¬ì„± (ì„ íƒ)
        """
        if pd.isna(text) or not text:
            return {
                'optimized_text': '',
                'original_length': 0,
                'optimized_length': 0,
                'keyword_count': 0,
                'changes': []
            }

        original_text = text
        original_length = len(text)
        all_changes = []

        # 1. # ì œëª© ì‚­ì œ
        text = self.remove_hashtag_title(text)
        all_changes.append('âœ… # ì œëª© ì‚­ì œ')

        # 2. í‚¤ì›Œë“œ+ì¡°ì‚¬ ì œê±°
        before_particle = text.count(keyword)
        text = self.remove_keyword_particles(text, keyword)
        after_particle = text.count(keyword)
        all_changes.append(f'âœ… í‚¤ì›Œë“œ+ì¡°ì‚¬ ì œê±° ({before_particle}íšŒ)')

        # 3. í‚¤ì›Œë“œ ì¶œí˜„ ê°ì†Œ (2-3íšŒ ëª©í‘œ)
        text = self.reduce_keyword_frequency(text, keyword, target_count=2)
        final_count = text.count(keyword)
        all_changes.append(f'âœ… í‚¤ì›Œë“œ ì¶œí˜„ ê°ì†Œ â†’ {final_count}íšŒ')

        # 4. ê¸ˆì¹™ì–´ ì¹˜í™˜
        text, forbidden_changes = self.replace_forbidden_words(text)
        if forbidden_changes:
            all_changes.append(f'âœ… ê¸ˆì¹™ì–´ {len(forbidden_changes)}ê°œ ì¹˜í™˜')

        # 5. AI íŒ¨í„´ ë‹¤ì–‘í™”
        text, ai_changes = self.diversify_ai_patterns(text)
        if ai_changes:
            all_changes.append(f'âœ… AI í‘œí˜„ {len(ai_changes)}ê°œ ìˆ˜ì •')

        # 6. ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•
        text = self.add_natural_variations(text)

        # 7. AI ì¬êµ¬ì„± (ì„ íƒ)
        if self.use_ai and self.ai_rewriter:
            try:
                print(f"  ğŸ¤– AI ì¬êµ¬ì„± ì¤‘...")
                ai_text = self.ai_rewriter.rewrite(text, keyword)
                if ai_text and len(ai_text) > 100:  # ìœ íš¨í•œ ê²°ê³¼ì¸ì§€ í™•ì¸
                    text = ai_text
                    all_changes.append('âœ… AI ìì—°ìŠ¤ëŸ¬ìš´ ì¬êµ¬ì„± ì™„ë£Œ')
                    # AI ì¬êµ¬ì„± í›„ í‚¤ì›Œë“œ ê°œìˆ˜ ì¬í™•ì¸
                    final_count = text.count(keyword)
            except Exception as e:
                print(f"  âš ï¸ AI ì¬êµ¬ì„± ì˜¤ë¥˜: {e}")
                all_changes.append('âš ï¸ AI ì¬êµ¬ì„± ì‹¤íŒ¨ (ì›ë³¸ ìœ ì§€)')

        # 8. í•´ì‹œíƒœê·¸ ìƒì„±
        hashtags = self.generate_hashtags(keyword, brand)

        # 9. ì œëª© ìƒì„±
        title = self.generate_title(keyword, text)

        return {
            'optimized_text': text,
            'optimized_title': title,
            'original_length': original_length,
            'optimized_length': len(text),
            'keyword_count': final_count,
            'changes': all_changes,
            'hashtags': hashtags,
            'length_diff': len(text) - original_length
        }

    def process_excel(self, input_file: str, output_file: str = None) -> str:
        """
        ì—‘ì…€ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬
        """
        if output_file is None:
            output_file = input_file.replace('.xlsx', '_ê²€ìƒ‰ìµœì í™”.xlsx')

        # ì—‘ì…€ ì½ê¸°
        df = pd.read_excel(input_file)

        # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
        if 'ìµœì í™”_ì›ê³ ' not in df.columns:
            df['ìµœì í™”_ì›ê³ '] = ''
        if 'í‚¤ì›Œë“œ_ì¶œí˜„' not in df.columns:
            df['í‚¤ì›Œë“œ_ì¶œí˜„'] = 0
        if 'ë³€ê²½ì‚¬í•­' not in df.columns:
            df['ë³€ê²½ì‚¬í•­'] = ''
        if 'ì¶”ì²œ_í•´ì‹œíƒœê·¸' not in df.columns:
            df['ì¶”ì²œ_í•´ì‹œíƒœê·¸'] = ''

        # ê° í–‰ ì²˜ë¦¬
        for idx, row in df.iterrows():
            keyword = row.get('í‚¤ì›Œë“œ', '')
            brand = row.get('ë¸Œëœë“œ', '')
            text = row.get('ì›ê³ ', '')

            if pd.isna(text) or not text:
                continue

            # ìµœì í™”
            result = self.optimize_for_search(text, keyword, brand)

            # ê²°ê³¼ ì €ì¥
            df.at[idx, 'ìµœì í™”_ì›ê³ '] = result['optimized_text']
            df.at[idx, 'í‚¤ì›Œë“œ_ì¶œí˜„'] = result['keyword_count']
            df.at[idx, 'ë³€ê²½ì‚¬í•­'] = '\n'.join(result['changes'])
            df.at[idx, 'ì¶”ì²œ_í•´ì‹œíƒœê·¸'] = ' '.join(['#' + tag for tag in result['hashtags'][:10]])

        # ì €ì¥
        df.to_excel(output_file, index=False)
        return output_file
