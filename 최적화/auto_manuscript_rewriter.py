#!/usr/bin/env python3
"""
Gemini APIë¥¼ ì‚¬ìš©í•œ ìë™ ì›ê³  ìˆ˜ì • ì‹œìŠ¤í…œ
- íšŒì‚¬ ê²€ìˆ˜ ê¸°ì¤€ì— ë§ê²Œ ìë™ìœ¼ë¡œ ì›ê³  ìˆ˜ì •
- ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë§¥ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ê°€/ì‚­ì œ
"""

import os
import re
import pandas as pd
from typing import Dict, List, Tuple
from collections import Counter
import google.generativeai as genai


class AutoManuscriptRewriter:
    """ì›ê³  ìë™ ê²€ìˆ˜ ë° ìˆ˜ì • ì‹œìŠ¤í…œ"""

    def __init__(self, forbidden_words_file='ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸.xlsx', gemini_api_key=None):
        """ì´ˆê¸°í™”"""
        self.forbidden_words_file = forbidden_words_file
        self.load_forbidden_words()

        # Gemini API ì„¤ì •
        api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ gemini_api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-pro')

    def load_forbidden_words(self):
        """ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
        try:
            df = pd.read_excel(self.forbidden_words_file)
            self.forbidden_words = {}

            for idx, row in df.iterrows():
                forbidden = row.iloc[1]  # Bì—´
                if pd.notna(forbidden) and forbidden != 'ê¸ˆì¹™ì–´':
                    alternatives = []
                    for i in range(2, len(row)):  # Cì—´ ì´í›„
                        if pd.notna(row.iloc[i]):
                            alternatives.append(str(row.iloc[i]))
                    if alternatives:
                        self.forbidden_words[str(forbidden)] = alternatives

            print(f"âœ… ê¸ˆì¹™ì–´ {len(self.forbidden_words)}ê°œ ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ ê¸ˆì¹™ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.forbidden_words = {}

    def get_first_paragraph(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì¶”ì¶œ"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return paragraphs[0].strip() if paragraphs else ""

    def get_rest_paragraphs(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì œì™¸í•œ ë‚˜ë¨¸ì§€"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return '\n\n'.join(paragraphs[1:]).strip() if len(paragraphs) > 1 else ""

    def count_keyword(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œ ì¹´ìš´íŒ… (ë„ì–´ì“°ê¸° ê¸°ì¤€)"""
        if not keyword or pd.isna(keyword):
            return 0
        pattern = rf'{re.escape(keyword)}(?=\s|[^\wê°€-í£]|$)'
        return len(re.findall(pattern, text))

    def count_sentences_starting_with(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(ì¤„) ê°œìˆ˜"""
        if not keyword:
            return 0
        count = 0
        for line in text.split('\n'):
            line = line.strip()
            if line.startswith(keyword):
                count += 1
        return count

    def count_sentences_between_keywords(self, paragraph: str, keyword: str) -> int:
        """ì²« ë¬¸ë‹¨ì—ì„œ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥ ê°œìˆ˜"""
        if not keyword or not paragraph:
            return 0

        sentences = []
        for line in paragraph.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                # ë¬¸ì¥ ë¶„ë¦¬ (., !, ? ê¸°ì¤€)
                parts = re.split(r'[.!?]\s*', line)
                sentences.extend([s.strip() for s in parts if s.strip()])

        # í‚¤ì›Œë“œ í¬í•¨ ë¬¸ì¥ ì¸ë±ìŠ¤ ì°¾ê¸°
        keyword_indices = []
        for i, sentence in enumerate(sentences):
            if keyword in sentence:
                keyword_indices.append(i)

        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥ ê°œìˆ˜
        if len(keyword_indices) >= 2:
            return keyword_indices[1] - keyword_indices[0] - 1

        return 0

    def count_subkeywords(self, text: str, exclude_keywords: List[str] = None) -> int:
        """ì„œë¸Œí‚¤ì›Œë“œ ëª©ë¡ ìˆ˜ (2íšŒ ì´ìƒ ë“±ì¥í•˜ëŠ” ë‹¨ì–´)"""
        if exclude_keywords is None:
            exclude_keywords = []

        words = re.findall(r'[ê°€-í£]+', text)
        punctuations = re.findall(r'([^\w\sê°€-í£])\1+', text)

        word_counter = Counter(words)
        punct_counter = Counter(punctuations)

        subkeywords = set()
        for word, count in word_counter.items():
            if count >= 2 and len(word) >= 2 and word not in exclude_keywords:
                subkeywords.add(word)

        for punct, count in punct_counter.items():
            if count >= 2:
                subkeywords.add(punct * 2)

        return len(subkeywords)

    def parse_target_value(self, value_str) -> Dict[str, int]:
        """D, Eì—´ ëª©í‘œê°’ íŒŒì‹±"""
        if pd.isna(value_str) or value_str == '-':
            return {}

        result = {}
        lines = str(value_str).split('\n')
        for line in lines:
            if ':' in line:
                parts = line.split(':')
                kw = parts[0].strip()
                count = int(parts[1].strip())
                result[kw] = count
        return result

    def analyze_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int) -> Dict:
        """ì›ê³  ë¶„ì„"""
        text_no_title = '\n'.join([line for line in manuscript.split('\n')
                                   if not line.strip().startswith('#')])

        ì²«ë¬¸ë‹¨ = self.get_first_paragraph(manuscript)
        ë‚˜ë¨¸ì§€ = self.get_rest_paragraphs(manuscript)

        target_whole = self.parse_target_value(target_whole_str)
        target_pieces = self.parse_target_value(target_pieces_str)

        # í˜„ì¬ ìƒíƒœ
        actual_chars = len(text_no_title.replace(' ', '').replace('\n', ''))
        ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ = self.count_keyword(ì²«ë¬¸ë‹¨, keyword)
        ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘ = self.count_sentences_starting_with(text_no_title, keyword)
        ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜ = self.count_sentences_between_keywords(ì²«ë¬¸ë‹¨, keyword)

        # ë‚˜ë¨¸ì§€ ë¶€ë¶„ í†µí‚¤ì›Œë“œ
        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ = {}
        for kw, target in target_whole.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual, 'diff': target - actual}

        # ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¡°ê°í‚¤ì›Œë“œ
        ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ = {}
        for kw, target in target_pieces.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual, 'diff': target - actual}

        # ì„œë¸Œí‚¤ì›Œë“œ
        exclude_list = [keyword] if keyword else []
        if target_pieces:
            exclude_list.extend(target_pieces.keys())
        actual_subkeywords = self.count_subkeywords(text_no_title, exclude_list)

        return {
            'chars': actual_chars,
            'chars_in_range': 300 <= actual_chars <= 900,
            'ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ': ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ,
            'í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘': ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘,
            'ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜': ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜,
            'ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ,
            'ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ,
            'subkeywords': {'target': target_subkeywords, 'actual': actual_subkeywords}
        }

    def create_rewrite_prompt(self, manuscript: str, keyword: str, analysis: Dict,
                             target_whole_str: str, target_pieces_str: str) -> str:
        """Geminiìš© ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸
        forbidden_list = list(self.forbidden_words.keys())[:30]  # ìƒìœ„ 30ê°œë§Œ

        # ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ ëª©ë¡
        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_rules = []
        for kw, data in analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
            ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_rules.append(f"  - [{kw}] ì •í™•íˆ {data['target']}íšŒ (ì²« ë¬¸ë‹¨ ì´í›„ ë¶€ë¶„ì—ì„œ)")

        # ì¡°ê°í‚¤ì›Œë“œ ëª©ë¡
        ì¡°ê°í‚¤ì›Œë“œ_rules = []
        for kw, data in analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
            ì¡°ê°í‚¤ì›Œë“œ_rules.append(f"  - [{kw}] ì •í™•íˆ {data['target']}íšŒ (ì²« ë¬¸ë‹¨ ì´í›„ ë¶€ë¶„ì—ì„œ)")

        # ì„œë¸Œí‚¤ì›Œë“œ ëª©í‘œ
        ì„œë¸Œí‚¤ì›Œë“œ_target = analysis['subkeywords']['target']

        # ì´ ê·œì¹™ ê°œìˆ˜
        rule_count = 4  # ê¸°ë³¸ 4ê°œ: ì²«ë¬¸ë‹¨ 2íšŒ, ë¬¸ì¥ì‹œì‘ 2ê°œ, í‚¤ì›Œë“œì‚¬ì´ 2ë¬¸ì¥, ê¸€ììˆ˜
        if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_rules:
            rule_count += 1
        if ì¡°ê°í‚¤ì›Œë“œ_rules:
            rule_count += 1
        if ì„œë¸Œí‚¤ì›Œë“œ_target > 0:
            rule_count += 1

        prompt = f"""ğŸ”´ ì ˆëŒ€ ê·œì¹™: ì•„ë˜ {rule_count}ê°œ ê¸°ì¤€ì„ ì •í™•íˆ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤. 1ê°œë¼ë„ ì–´ê¸°ë©´ ì‹¤ê²©ì…ë‹ˆë‹¤.

ì‘ì—… ë°©ì‹:
- ì›ë³¸ ê¸€ ë‚´ìš© ìµœëŒ€í•œ ìœ ì§€
- í‚¤ì›Œë“œë§Œ ì¶”ê°€í•˜ê±°ë‚˜ ìœ„ì¹˜ ì¡°ì •
- ê¸€ì„ ì²˜ìŒë¶€í„° ìƒˆë¡œ ì“°ì§€ ë§ ê²ƒ!

ê¸€ êµ¬ì¡° (í•„ìˆ˜):
âœ… ë„ì…ë¶€: ë¶ˆí¸í•¨ì´ë‚˜ ê³ ë¯¼ í‘œí˜„ (ì˜ˆ: "~ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìŠµë‹ˆë‹¤", "~ë¡œ í˜ë“¤ì–´ìš”")
âœ… ë§ˆë¬´ë¦¬: ëŒ“ê¸€ ìœ ë„ ë˜ëŠ” ì •ë³´ ê³µìœ  ìš”ì²­ (ì˜ˆ: "ì •ë³´ ê³µìœ  ë¶€íƒë“œë ¤ìš”", "ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”")

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ ì—„ê²©í•œ ê¸°ì¤€ ({rule_count}ê°œ ëª¨ë‘ ì •í™•íˆ ì§€ì¼œì•¼ í•¨!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í‚¤ì›Œë“œ: {keyword}

ğŸ”´ ê·œì¹™ 1: ì²« ë¬¸ë‹¨ì— [{keyword}] ì •í™•íˆ 2ë²ˆ
   - 1ë²ˆ âŒ, 2ë²ˆ âœ…, 3ë²ˆ âŒ
   - ì¡°ì‚¬ ë¶™ìœ¼ë©´ ì¹´ìš´íŒ… ì•ˆ ë¨!
   - ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ [{keyword}] ì‚¬ì´ì— ìµœì†Œ 2ë¬¸ì¥ ì´ìƒ ìˆì–´ì•¼ í•¨!

ğŸ”´ ê·œì¹™ 2: [{keyword}]ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì •í™•íˆ 2ê°œ
   - 1ê°œ âŒ, 2ê°œ âœ…, 3ê°œ âŒ
   - ì¤„ ë§¨ ì•ì—ì„œ ì‹œì‘í•´ì•¼ í•¨!

ğŸ”´ ê·œì¹™ 3: ì²« ë¬¸ë‹¨ í‚¤ì›Œë“œ ì‚¬ì´ì— 2ë¬¸ì¥ ì´ìƒ
   - ì²« ë²ˆì§¸ [{keyword}]ì™€ ë‘ ë²ˆì§¸ [{keyword}] ì‚¬ì´ ìµœì†Œ 2ë¬¸ì¥

ğŸ”´ ê·œì¹™ 4: ê¸€ììˆ˜ 300~900ì (ê³µë°± ì œì™¸)"""

        # ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ
        rule_num = 5
        if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_rules:
            prompt += f"""

ğŸ”´ ê·œì¹™ {rule_num}: ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ (ì²« ë¬¸ë‹¨ ì´í›„)"""
            for kw, data in analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
                prompt += f"""
   - [{kw}] ì •í™•íˆ {data['target']}íšŒ (Â±1ë„ ì•ˆ ë¨!)"""
            rule_num += 1

        # ì¡°ê°í‚¤ì›Œë“œ
        if ì¡°ê°í‚¤ì›Œë“œ_rules:
            prompt += f"""

ğŸ”´ ê·œì¹™ {rule_num}: ì¡°ê°í‚¤ì›Œë“œ (ì²« ë¬¸ë‹¨ ì´í›„)"""
            for kw, data in analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
                prompt += f"""
   - [{kw}] ì •í™•íˆ {data['target']}íšŒ (Â±1ë„ ì•ˆ ë¨!)"""
            rule_num += 1

        # ì„œë¸Œí‚¤ì›Œë“œ
        if ì„œë¸Œí‚¤ì›Œë“œ_target > 0:
            prompt += f"""

ğŸ”´ ê·œì¹™ {rule_num}: ì„œë¸Œí‚¤ì›Œë“œ {ì„œë¸Œí‚¤ì›Œë“œ_target}ê°œ ì´ìƒ
   - 2íšŒ ì´ìƒ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ {ì„œë¸Œí‚¤ì›Œë“œ_target}ê°œ ì´ìƒ
   - ^^, ??, ..., ;;, !! ê°™ì€ ì¤‘ë³µ ë¬¸ì¥ë¶€í˜¸ë„ 2íšŒ ì´ìƒ ì‚¬ìš©í•˜ë©´ ì¹´ìš´íŒ…ë¨"""

        # ê¸ˆì¹™ì–´
        forbidden_list = list(self.forbidden_words.keys())[:10]
        if forbidden_list:
            prompt += f"""

ğŸš« ê¸ˆì¹™ì–´ ì¹˜í™˜ í•„ìˆ˜:
{chr(10).join(f'   - {word} â†’ {", ".join(self.forbidden_words[word][:2])}' for word in forbidden_list)}
(ì „ì²´ {len(self.forbidden_words)}ê°œ)"""

        prompt += f"""

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ ì¹´ìš´íŒ… ê·œì¹™ (ì¤‘ìš”!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âŒ ì¡°ì‚¬ ë¶™ìœ¼ë©´ ì¹´ìš´íŒ… ì•ˆ ë¨:
   {keyword}ì—, {keyword}ë¥¼, {keyword}ê°€ ë“±

âœ… ë„ì–´ì“°ê¸° ìˆìœ¼ë©´ ì¹´ìš´íŒ…ë¨:
   {keyword} ê´€ë ¨í•´ì„œ, {keyword} ë•Œë¬¸ì—, {keyword} ì •ë³´ë¥¼

ğŸ“Œ ì¡°ì‚¬ ì²˜ë¦¬ ê°€ì´ë“œ:
   - í•œ ê¸€ì ì¡°ì‚¬ (ì—, ë¥¼, ê°€, ì€, ì´): ìš°íšŒ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
     ì˜ˆ) "{keyword}ì— ëŒ€í•´" â†’ "{keyword} ê´€ë ¨í•´ì„œ"
   - ë‘ ê¸€ì ì´ìƒ ì¡°ì‚¬ (ì—ì„œ, ì—ê²Œ, ìœ¼ë¡œ): ë„ì–´ì“°ê¸°ë¡œ ê°€ëŠ¥
     ì˜ˆ) "{keyword}ì—ì„œ" â†’ "{keyword} ì—ì„œ" (ë„ì–´ì“°ê¸°)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ ì›ë³¸ ì›ê³ 
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{manuscript}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ì¶œë ¥ ì „ ì§ì ‘ ì„¸ì–´ë³´ê¸°!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì¶œë ¥ ì „ ë°˜ë“œì‹œ í™•ì¸:
âœ“ ì²« ë¬¸ë‹¨ [{keyword} ]: ì •í™•íˆ 2ë²ˆ?
âœ“ ë¬¸ì¥ ì‹œì‘ [{keyword}]: ì •í™•íˆ 2ê°œ?
âœ“ ê¸€ììˆ˜: 300~900ì?"""

        if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_rules:
            for kw, data in analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
                prompt += f"""
âœ“ [{kw}]: ì •í™•íˆ {data['target']}íšŒ?"""

        if ì¡°ê°í‚¤ì›Œë“œ_rules:
            for kw, data in analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
                prompt += f"""
âœ“ [{kw}]: ì •í™•íˆ {data['target']}íšŒ?"""

        if ì„œë¸Œí‚¤ì›Œë“œ_target > 0:
            prompt += f"""
âœ“ ì„œë¸Œí‚¤ì›Œë“œ: {ì„œë¸Œí‚¤ì›Œë“œ_target}ê°œ ì´ìƒ?"""

        prompt += """

ìˆ˜ì •ëœ ì›ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        return prompt

    def rewrite_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int, max_retries: int = 3) -> Dict:
        """ì›ê³  ìë™ ìˆ˜ì • (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""

        # 1. ë¶„ì„
        analysis = self.analyze_manuscript(manuscript, keyword, target_whole_str,
                                          target_pieces_str, target_subkeywords)

        print(f"\n{'=' * 100}")
        print(f"ì›ê³  ë¶„ì„ - í‚¤ì›Œë“œ: {keyword}")
        print(f"{'=' * 100}")
        print(f"ê¸€ììˆ˜: {analysis['chars']}ì (ëª©í‘œ: 300~900ì)")
        print(f"ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ (ëª©í‘œ: 2íšŒ)")
        print(f"í†µí‚¤ì›Œë“œ ë¬¸ì¥ ì‹œì‘: {analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ (ëª©í‘œ: 2ê°œ)")

        # ì¬ì‹œë„ ë£¨í”„
        rewritten = None  # ì´ˆê¸°í™”
        after_analysis = None  # ì´ˆê¸°í™”

        for attempt in range(max_retries):
            print(f"\nğŸ¤– Geminiê°€ ì›ê³ ë¥¼ ìˆ˜ì • ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries})")

            try:
                # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
                if attempt == 0 or rewritten is None:
                    # ì²« ì‹œë„ì´ê±°ë‚˜ ì´ì „ ì‹œë„ì—ì„œ rewrittenì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
                    prompt = self.create_rewrite_prompt(manuscript, keyword, analysis,
                                                       target_whole_str, target_pieces_str)
                else:
                    # ì¬ì‹œë„ ì‹œ ì´ì „ ì‹¤íŒ¨ ì´ìœ  í¬í•¨
                    prompt = self.create_retry_prompt(manuscript, keyword, rewritten,
                                                     after_analysis, target_whole_str,
                                                     target_pieces_str)

                # 3. Geminië¡œ ìˆ˜ì •
                response = self.model.generate_content(prompt)
                rewritten = response.text.strip()

                # 4. ìˆ˜ì • í›„ ì¬ë¶„ì„
                after_analysis = self.analyze_manuscript(rewritten, keyword, target_whole_str,
                                                        target_pieces_str, target_subkeywords)

                # 5. ê²€ì¦ - ALL 7ê°œ ê¸°ì¤€ì„ ì •í™•íˆ ì²´í¬
                first_para_ok = after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ'] == 2
                sentence_start_ok = after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘'] == 2
                í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜_ok = after_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜'] >= 2
                chars_ok = after_analysis['chars_in_range']

                # ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ ê²€ì¦ (ëª¨ë“  í‚¤ì›Œë“œê°€ ì •í™•íˆ ëª©í‘œ íšŸìˆ˜ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
                ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok = True
                ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_errors = []
                for kw, data in after_analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
                    if data['actual'] != data['target']:
                        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok = False
                        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_errors.append(f"{kw}: {data['actual']}íšŒ (ëª©í‘œ: {data['target']}íšŒ)")

                # ì¡°ê°í‚¤ì›Œë“œ ê²€ì¦ (ëª¨ë“  ì¡°ê°í‚¤ì›Œë“œê°€ ì •í™•íˆ ëª©í‘œ íšŸìˆ˜ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
                ì¡°ê°í‚¤ì›Œë“œ_ok = True
                ì¡°ê°í‚¤ì›Œë“œ_errors = []
                for kw, data in after_analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
                    if data['actual'] != data['target']:
                        ì¡°ê°í‚¤ì›Œë“œ_ok = False
                        ì¡°ê°í‚¤ì›Œë“œ_errors.append(f"{kw}: {data['actual']}íšŒ (ëª©í‘œ: {data['target']}íšŒ)")

                # ì„œë¸Œí‚¤ì›Œë“œ ê²€ì¦ (ëª©í‘œ ì´ìƒì´ì–´ì•¼ í•¨)
                ì„œë¸Œí‚¤ì›Œë“œ_ok = after_analysis['subkeywords']['actual'] >= after_analysis['subkeywords']['target']

                # ALL 7ê°œ ê¸°ì¤€ì´ ëª¨ë‘ ì¶©ì¡±ë˜ì–´ì•¼ ì„±ê³µ
                all_criteria_met = (first_para_ok and sentence_start_ok and í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜_ok and
                                   chars_ok and ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok and ì¡°ê°í‚¤ì›Œë“œ_ok and ì„œë¸Œí‚¤ì›Œë“œ_ok)

                print(f"\n{'=' * 100}")
                print(f"ìˆ˜ì • í›„ ê²€ì¦ ê²°ê³¼:")
                print(f"  1. ê¸€ììˆ˜: {after_analysis['chars']}ì {'âœ…' if chars_ok else 'âŒ'}")
                print(f"  2. ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ {'âœ…' if first_para_ok else 'âŒ'}")
                print(f"  3. í†µí‚¤ì›Œë“œ ë¬¸ì¥ ì‹œì‘: {after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ {'âœ…' if sentence_start_ok else 'âŒ'}")
                print(f"  4. ì²«ë¬¸ë‹¨ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥: {after_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜']}ê°œ (ìµœì†Œ 2ê°œ) {'âœ…' if í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜_ok else 'âŒ'}")

                # ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ ì¶œë ¥
                print(f"  5. ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ: {'âœ…' if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok else 'âŒ'}")
                if not ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok:
                    for err in ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_errors:
                        print(f"     - {err}")
                else:
                    for kw, data in after_analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
                        print(f"     - {kw}: {data['actual']}/{data['target']}íšŒ âœ…")

                # ì¡°ê°í‚¤ì›Œë“œ ì¶œë ¥
                print(f"  6. ì¡°ê°í‚¤ì›Œë“œ: {'âœ…' if ì¡°ê°í‚¤ì›Œë“œ_ok else 'âŒ'}")
                if not ì¡°ê°í‚¤ì›Œë“œ_ok:
                    for err in ì¡°ê°í‚¤ì›Œë“œ_errors:
                        print(f"     - {err}")
                else:
                    for kw, data in after_analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
                        print(f"     - {kw}: {data['actual']}/{data['target']}íšŒ âœ…")

                # ì„œë¸Œí‚¤ì›Œë“œ ì¶œë ¥
                print(f"  7. ì„œë¸Œí‚¤ì›Œë“œ ëª©ë¡: {after_analysis['subkeywords']['actual']}ê°œ (ëª©í‘œ: {after_analysis['subkeywords']['target']}ê°œ ì´ìƒ) {'âœ…' if ì„œë¸Œí‚¤ì›Œë“œ_ok else 'âŒ'}")

                # ALL ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ í™•ì¸
                if all_criteria_met:
                    print(f"\nâœ… ì„±ê³µ! ëª¨ë“  ê¸°ì¤€ ì¶©ì¡± (7/7)")
                    return {
                        'success': True,
                        'original': manuscript,
                        'rewritten': rewritten,
                        'before_analysis': analysis,
                        'after_analysis': after_analysis,
                        'attempts': attempt + 1
                    }
                else:
                    # ì‹¤íŒ¨í•œ ê¸°ì¤€ í‘œì‹œ
                    failed_count = sum([
                        not chars_ok,
                        not first_para_ok,
                        not sentence_start_ok,
                        not í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜_ok,
                        not ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_ok,
                        not ì¡°ê°í‚¤ì›Œë“œ_ok,
                        not ì„œë¸Œí‚¤ì›Œë“œ_ok
                    ])
                    print(f"\nâš ï¸ ê¸°ì¤€ ë¯¸ë‹¬ ({7-failed_count}/7 ì¶©ì¡±), ì¬ì‹œë„ í•„ìš”...")
                    continue

            except Exception as e:
                print(f"âŒ ìˆ˜ì • ì‹¤íŒ¨: {e}")
                if attempt == max_retries - 1:
                    return {
                        'success': False,
                        'error': str(e),
                        'original': manuscript
                    }
                continue

        # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
        print(f"âš ï¸ {max_retries}íšŒ ì‹œë„ í›„ì—ë„ ê¸°ì¤€ ë¯¸ë‹¬")
        return {
            'success': False,
            'error': f'{max_retries}íšŒ ì¬ì‹œë„ í›„ì—ë„ ê¸°ì¤€ ì¶©ì¡± ì‹¤íŒ¨',
            'original': manuscript,
            'rewritten': rewritten,
            'after_analysis': after_analysis,
            'attempts': max_retries
        }

    def create_retry_prompt(self, original: str, keyword: str, failed_text: str,
                           failed_analysis: Dict, target_whole_str: str,
                           target_pieces_str: str) -> str:
        """ì¬ì‹œë„ìš© í”„ë¡¬í”„íŠ¸ (ì´ì „ ì‹¤íŒ¨ ì´ìœ  í¬í•¨ - ALL 7ê°œ ê¸°ì¤€)"""

        first_para_count = failed_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']
        sentence_start_count = failed_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']
        í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜ = failed_analysis['ì²«ë¬¸ë‹¨_í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜']
        chars = failed_analysis['chars']
        chars_ok = failed_analysis['chars_in_range']

        # ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ ìƒíƒœ
        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status = []
        for kw, data in failed_analysis['ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ'].items():
            icon = 'âœ…' if data['actual'] == data['target'] else 'âŒ'
            ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status.append(f"{kw}: {data['actual']}íšŒ (ëª©í‘œ: {data['target']}íšŒ) {icon}")

        # ì¡°ê°í‚¤ì›Œë“œ ìƒíƒœ
        ì¡°ê°í‚¤ì›Œë“œ_status = []
        for kw, data in failed_analysis['ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ'].items():
            icon = 'âœ…' if data['actual'] == data['target'] else 'âŒ'
            ì¡°ê°í‚¤ì›Œë“œ_status.append(f"{kw}: {data['actual']}íšŒ (ëª©í‘œ: {data['target']}íšŒ) {icon}")

        # ì„œë¸Œí‚¤ì›Œë“œ ìƒíƒœ
        sub_actual = failed_analysis['subkeywords']['actual']
        sub_target = failed_analysis['subkeywords']['target']
        sub_ok = sub_actual >= sub_target

        prompt = f"""ì´ì „ ìˆ˜ì •ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

âš ï¸ **ìµœìš°ì„ **: ALL 7ê°œ ê·œì¹™ì„ ì •í™•íˆ ì§€í‚¤ì„¸ìš”! ê·œì¹™ ì¤€ìˆ˜ê°€ 1ìˆœìœ„ì…ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âŒ ì´ì „ ì‹¤íŒ¨ ì´ìœ  (7ê°œ ê¸°ì¤€ ê²€ì¦ ê²°ê³¼)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í‚¤ì›Œë“œ: **{keyword}**

1. ê¸€ììˆ˜: {chars}ì (ëª©í‘œ: 300-900ì) {'âœ…' if chars_ok else 'âŒ'}
2. ì²« ë¬¸ë‹¨ [{keyword}] ì¹´ìš´íŒ…: {first_para_count}íšŒ (ëª©í‘œ: ì •í™•íˆ 2íšŒ) {'âœ…' if first_para_count == 2 else 'âŒ'}
3. ë¬¸ì¥ ì‹œì‘ [{keyword}] ê°œìˆ˜: {sentence_start_count}ê°œ (ëª©í‘œ: ì •í™•íˆ 2ê°œ) {'âœ…' if sentence_start_count == 2 else 'âŒ'}
4. ì²« ë¬¸ë‹¨ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥: {í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜}ê°œ (ëª©í‘œ: ìµœì†Œ 2ê°œ) {'âœ…' if í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜ >= 2 else 'âŒ'}
5. ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ:
   {chr(10).join('   - ' + s for s in ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status) if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status else '   (ì—†ìŒ)'}
6. ì¡°ê°í‚¤ì›Œë“œ:
   {chr(10).join('   - ' + s for s in ì¡°ê°í‚¤ì›Œë“œ_status) if ì¡°ê°í‚¤ì›Œë“œ_status else '   (ì—†ìŒ)'}
7. ì„œë¸Œí‚¤ì›Œë“œ: {sub_actual}ê°œ (ëª©í‘œ: {sub_target}ê°œ ì´ìƒ) {'âœ…' if sub_ok else 'âŒ'}

**ì´ì „ì— ì‘ì„±í•œ ì›ê³ :**
{failed_text}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ ë‹¤ì‹œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ (ALL 7ê°œ ê¸°ì¤€ ì¶©ì¡± í•„ìˆ˜!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ê¸°ë³¸ ê·œì¹™ 1: ì²« ë¬¸ë‹¨ì— [{keyword}] ì •í™•íˆ 2ë²ˆ**
- í˜„ì¬: {first_para_count}ë²ˆ â†’ ëª©í‘œ: 2ë²ˆ
- âš ï¸ 3ë²ˆ ì´ìƒ ì ˆëŒ€ ì•ˆ ë¨! ì •í™•íˆ 2ë²ˆë§Œ!

**ê¸°ë³¸ ê·œì¹™ 2: [{keyword}]ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì •í™•íˆ 2ê°œ**
- í˜„ì¬: {sentence_start_count}ê°œ â†’ ëª©í‘œ: 2ê°œ
- âš ï¸ 3ê°œ ì´ìƒ ì ˆëŒ€ ì•ˆ ë¨! ì •í™•íˆ 2ê°œë§Œ!

**ê¸°ë³¸ ê·œì¹™ 3: ì²« ë¬¸ë‹¨ í‚¤ì›Œë“œ ì‚¬ì´ ë¬¸ì¥ ìµœì†Œ 2ê°œ**
- í˜„ì¬: {í‚¤ì›Œë“œì‚¬ì´_ë¬¸ì¥ìˆ˜}ê°œ â†’ ëª©í‘œ: ìµœì†Œ 2ê°œ
- âš ï¸ ì²« ë²ˆì§¸ [{keyword}]ì™€ ë‘ ë²ˆì§¸ [{keyword}] ì‚¬ì´ì— ë¬¸ì¥ 2ê°œ ì´ìƒ!

**ì¶”ê°€ ê·œì¹™ 4: ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œ ì •í™•í•œ íšŸìˆ˜ ì‚¬ìš©**
{chr(10).join('- ' + s for s in ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status) if ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ_status else '(ì—†ìŒ)'}

**ì¶”ê°€ ê·œì¹™ 5: ì¡°ê°í‚¤ì›Œë“œ ì •í™•í•œ íšŸìˆ˜ ì‚¬ìš©**
{chr(10).join('- ' + s for s in ì¡°ê°í‚¤ì›Œë“œ_status) if ì¡°ê°í‚¤ì›Œë“œ_status else '(ì—†ìŒ)'}

**ì¶”ê°€ ê·œì¹™ 6: ì„œë¸Œí‚¤ì›Œë“œ ëª©ë¡ ìˆ˜ ì¶©ì¡±**
- í˜„ì¬: {sub_actual}ê°œ â†’ ëª©í‘œ: {sub_target}ê°œ ì´ìƒ

**ì¶”ê°€ ê·œì¹™ 7: ê¸€ììˆ˜ ë²”ìœ„**
- í˜„ì¬: {chars}ì â†’ ëª©í‘œ: 300-900ì

**ì ˆëŒ€ ê¸ˆì§€ íŒ¨í„´ (ì¡°ì‚¬ ë¶™ìœ¼ë©´ ì¹´ìš´íŒ… ì•ˆ ë¨!):**
âŒ {keyword}ì— âŒ {keyword}ì—ì„œ âŒ {keyword}ë¥¼ âŒ {keyword}ê°€

**ì˜¬ë°”ë¥¸ íŒ¨í„´ (ë„ì–´ì“°ê¸°!):**
âœ… {keyword} ê´€ë ¨í•´ì„œ âœ… {keyword} ë•Œë¬¸ì— âœ… {keyword} í›„ê¸°ë¥¼

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ ì›ë³¸ ì›ê³ 
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{original}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ì´ë²ˆì—” ë°˜ë“œì‹œ ALL 7ê°œ ê·œì¹™ ì¤€ìˆ˜!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸: (ëª¨ë‘ ì ˆëŒ€ ì¤€ìˆ˜!)**
1. ì²« ë¬¸ë‹¨ì—ì„œ [{keyword} ] (ë„ì–´ì“°ê¸°) íŒ¨í„´ì„ ì •í™•íˆ 2ë²ˆ ì‚¬ìš© (1ë²ˆâŒ 3ë²ˆâŒ)
2. ì¤„ ë§¨ ì•ì— [{keyword} ]ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì„ ì •í™•íˆ 2ê°œ ì‘ì„± (1ê°œâŒ 3ê°œâŒ)
3. ì²« ë¬¸ë‹¨ì—ì„œ ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ [{keyword}] ì‚¬ì´ì— ë¬¸ì¥ ìµœì†Œ 2ê°œ ë°°ì¹˜
4. ë‚˜ë¨¸ì§€ í†µí‚¤ì›Œë“œë¥¼ ì •í™•íˆ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ì‚¬ìš©
5. ì¡°ê°í‚¤ì›Œë“œë¥¼ ì •í™•íˆ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ì‚¬ìš©
6. ì„œë¸Œí‚¤ì›Œë“œë¥¼ ì§€ì •ëœ ê°œìˆ˜ ì´ìƒ ì‚¬ìš© (^^, ??, ... ê°™ì€ ì¤‘ë³µ ë¬¸ì¥ë¶€í˜¸ë„ ì¹´ìš´íŒ…ë¨!)
7. ê¸€ììˆ˜ë¥¼ 300-900ì ë²”ìœ„ ë‚´ë¡œ ì‘ì„±
8. ì¡°ì‚¬ ì ˆëŒ€ ê¸ˆì§€! (í•œ ê¸€ì ì¡°ì‚¬ëŠ” ìš°íšŒ, ë‘ ê¸€ì ì´ìƒì€ ë„ì–´ì“°ê¸°)

**ìš°ì„ ìˆœìœ„:**
1ìˆœìœ„: ìœ„ ALL 7ê°œ ê·œì¹™ ì •í™•íˆ ì§€í‚¤ê¸° (í•„ìˆ˜!)
2ìˆœìœ„: ê°€ëŠ¥í•˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ (ê·œì¹™ ì§€í‚¨ ìƒíƒœì—ì„œë§Œ)

ìˆ˜ì •ëœ ì›ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´).
"""
        return prompt


def test_rewriter():
    """í…ŒìŠ¤íŠ¸"""

    # API í‚¤ í™•ì¸
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    rewriter = AutoManuscriptRewriter()

    # í…ŒìŠ¤íŠ¸ ì›ê³ 
    test_manuscript = """ê°±ë…„ê¸°í™ì¡° ë•Œë¬¸ì— ì •ë§ ê³ ë¯¼ì´ ë§ìŠµë‹ˆë‹¤.
ì €ëŠ” 50ëŒ€ ì¤‘ë°˜ì¸ë° ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”.
ê°±ë…„ê¸°í™ì¡°ê°€ ì‹œì‘ëœ ì§€ 6ê°œì›”ì´ ë„˜ì—ˆëŠ”ë° ì¦ìƒì´ ì‹¬í•´ìš”.
ì–¼êµ´ì´ í™”ëˆê±°ë¦¬ê³  ì—´ì´ ì˜¬ë¼ìš”.
ë³‘ì›ì—ì„œ ì¹˜ë£Œë„ ë°›ì•„ë´¤ëŠ”ë° ë¶€ì‘ìš©ì´ ê±±ì •ë˜ë”ë¼ê³ ìš”.
íš¨ê³¼ê°€ ìˆëŠ” ë°©ë²• ì¢€ ì•Œë ¤ì£¼ì„¸ìš”."""

    keyword = "ê°±ë…„ê¸°í™ì¡°"
    target_whole = "ê°±ë…„ê¸°í™ì¡° : 0"
    target_pieces = "-"
    target_subkeywords = 5

    result = rewriter.rewrite_manuscript(test_manuscript, keyword, target_whole,
                                        target_pieces, target_subkeywords)

    if result['success']:
        print(f"\n\n{'=' * 100}")
        print("ìˆ˜ì •ëœ ì›ê³ :")
        print(f"{'=' * 100}")
        print(result['rewritten'])


if __name__ == '__main__':
    test_rewriter()
