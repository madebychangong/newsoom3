#!/usr/bin/env python3
"""
Gemini APIë¥¼ ì‚¬ìš©í•œ ìë™ ì›ê³  ìˆ˜ì • ì‹œìŠ¤í…œ
- íšŒì‚¬ ê²€ìˆ˜ ê¸°ì¤€ì— ë§ê²Œ ìë™ìœ¼ë¡œ ì›ê³  ìˆ˜ì •
- ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë§¥ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ê°€/ì‚­ì œ
"""

import os
import re
import pandas as pd
from typing import Dict, List, Tuple
from collections import Counter
import google.generativeai as genai


class AutoManuscriptRewriter:
    """ì›ê³  ìë™ ê²€ìˆ˜ ë° ìˆ˜ì • ì‹œìŠ¤í…œ"""

    def __init__(self, forbidden_words_file='ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸.xlsx', gemini_api_key=None):
        """ì´ˆê¸°í™”"""
        self.forbidden_words_file = forbidden_words_file
        self.load_forbidden_words()

        # Gemini API ì„¤ì •
        api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ gemini_api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')

    def load_forbidden_words(self):
        """ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
        try:
            df = pd.read_excel(self.forbidden_words_file)
            self.forbidden_words = {}

            for idx, row in df.iterrows():
                forbidden = row.iloc[1]  # Bì—´
                if pd.notna(forbidden) and forbidden != 'ê¸ˆì¹™ì–´':
                    alternatives = []
                    for i in range(2, len(row)):  # Cì—´ ì´í›„
                        if pd.notna(row.iloc[i]):
                            alternatives.append(str(row.iloc[i]))
                    if alternatives:
                        self.forbidden_words[str(forbidden)] = alternatives

            print(f"âœ… ê¸ˆì¹™ì–´ {len(self.forbidden_words)}ê°œ ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ ê¸ˆì¹™ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.forbidden_words = {}

    def get_first_paragraph(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì¶”ì¶œ"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return paragraphs[0].strip() if paragraphs else ""

    def get_rest_paragraphs(self, text: str) -> str:
        """ì²« ë¬¸ë‹¨ ì œì™¸í•œ ë‚˜ë¨¸ì§€"""
        lines = [line for line in text.split('\n') if not line.strip().startswith('#')]
        text_no_title = '\n'.join(lines)
        paragraphs = text_no_title.split('\n\n')
        return '\n\n'.join(paragraphs[1:]).strip() if len(paragraphs) > 1 else ""

    def count_keyword(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œ ì¹´ìš´íŒ… (ë„ì–´ì“°ê¸° ê¸°ì¤€)"""
        if not keyword or pd.isna(keyword):
            return 0
        pattern = rf'{re.escape(keyword)}(?=\s|[^\wê°€-í£]|$)'
        return len(re.findall(pattern, text))

    def count_sentences_starting_with(self, text: str, keyword: str) -> int:
        """í‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(ì¤„) ê°œìˆ˜"""
        if not keyword:
            return 0
        count = 0
        for line in text.split('\n'):
            line = line.strip()
            if line.startswith(keyword):
                count += 1
        return count

    def count_subkeywords(self, text: str, exclude_keywords: List[str] = None) -> int:
        """ì„œë¸Œí‚¤ì›Œë“œ ëª©ë¡ ìˆ˜ (2íšŒ ì´ìƒ ë“±ì¥í•˜ëŠ” ë‹¨ì–´)"""
        if exclude_keywords is None:
            exclude_keywords = []

        words = re.findall(r'[ê°€-í£]+', text)
        punctuations = re.findall(r'([^\w\sê°€-í£])\1+', text)

        word_counter = Counter(words)
        punct_counter = Counter(punctuations)

        subkeywords = set()
        for word, count in word_counter.items():
            if count >= 2 and len(word) >= 2 and word not in exclude_keywords:
                subkeywords.add(word)

        for punct, count in punct_counter.items():
            if count >= 2:
                subkeywords.add(punct * 2)

        return len(subkeywords)

    def parse_target_value(self, value_str) -> Dict[str, int]:
        """D, Eì—´ ëª©í‘œê°’ íŒŒì‹±"""
        if pd.isna(value_str) or value_str == '-':
            return {}

        result = {}
        lines = str(value_str).split('\n')
        for line in lines:
            if ':' in line:
                parts = line.split(':')
                kw = parts[0].strip()
                count = int(parts[1].strip())
                result[kw] = count
        return result

    def analyze_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int) -> Dict:
        """ì›ê³  ë¶„ì„"""
        text_no_title = '\n'.join([line for line in manuscript.split('\n')
                                   if not line.strip().startswith('#')])

        ì²«ë¬¸ë‹¨ = self.get_first_paragraph(manuscript)
        ë‚˜ë¨¸ì§€ = self.get_rest_paragraphs(manuscript)

        target_whole = self.parse_target_value(target_whole_str)
        target_pieces = self.parse_target_value(target_pieces_str)

        # í˜„ì¬ ìƒíƒœ
        actual_chars = len(text_no_title.replace(' ', '').replace('\n', ''))
        ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ = self.count_keyword(ì²«ë¬¸ë‹¨, keyword)
        ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘ = self.count_sentences_starting_with(text_no_title, keyword)

        # ë‚˜ë¨¸ì§€ ë¶€ë¶„ í†µí‚¤ì›Œë“œ
        ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ = {}
        for kw, target in target_whole.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual, 'diff': target - actual}

        # ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¡°ê°í‚¤ì›Œë“œ
        ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ = {}
        for kw, target in target_pieces.items():
            actual = self.count_keyword(ë‚˜ë¨¸ì§€, kw)
            ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ[kw] = {'target': target, 'actual': actual, 'diff': target - actual}

        # ì„œë¸Œí‚¤ì›Œë“œ
        exclude_list = [keyword] if keyword else []
        if target_pieces:
            exclude_list.extend(target_pieces.keys())
        actual_subkeywords = self.count_subkeywords(text_no_title, exclude_list)

        return {
            'chars': actual_chars,
            'chars_in_range': 300 <= actual_chars <= 900,
            'ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ': ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ,
            'í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘': ì „ì²´_í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘,
            'ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_í†µí‚¤ì›Œë“œ,
            'ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ': ë‚˜ë¨¸ì§€_ì¡°ê°í‚¤ì›Œë“œ,
            'subkeywords': {'target': target_subkeywords, 'actual': actual_subkeywords}
        }

    def create_rewrite_prompt(self, manuscript: str, keyword: str, analysis: Dict,
                             target_whole_str: str, target_pieces_str: str) -> str:
        """Geminiìš© ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸
        forbidden_list = list(self.forbidden_words.keys())[:30]  # ìƒìœ„ 30ê°œë§Œ

        prompt = f"""ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ì›ê³ ë¥¼ íšŒì‚¬ ê²€ìˆ˜ ê¸°ì¤€ì— ë§ê²Œ ìˆ˜ì •í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì›ë³¸ ì›ê³  (ì°¸ê³ ìš© - í†¤&ë§¤ë„ˆë§Œ í™œìš©)
{manuscript}

# í•µì‹¬ í‚¤ì›Œë“œ
í†µ í‚¤ì›Œë“œ: {keyword}

# ëª©í‘œ ìƒíƒœ
- ê¸€ììˆ˜: 300~900ì (ê³µë°±/ì¤„ë°”ê¿ˆ ì œì™¸)
- ì²« ë¬¸ë‹¨: í†µí‚¤ì›Œë“œ ì •í™•íˆ 2íšŒ, í†µí‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ 2ê°œ
- ë‚˜ë¨¸ì§€ ë¶€ë¶„ í†µí‚¤ì›Œë“œ: {target_whole_str}
- ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¡°ê°í‚¤ì›Œë“œ: {target_pieces_str}
- ì„œë¸Œí‚¤ì›Œë“œ: {analysis['subkeywords']['target']}ê°œ

# ê¸ˆì¹™ì–´ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)
{', '.join(forbidden_list)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ¯ í•µì‹¬ ìˆ˜ì • ì „ëµ

## âš ï¸ ê°€ì¥ ì¤‘ìš”: í‚¤ì›Œë“œ ì£¼ì œ ì¤‘ì‹¬ìœ¼ë¡œ ì›ê³  ì¬êµ¬ì„±
- **ì›ë³¸ ì›ê³ ì˜ ì£¼ì œê°€ í‚¤ì›Œë“œì™€ ì•ˆ ë§ìœ¼ë©´, í‚¤ì›Œë“œ ì£¼ì œë¡œ ë‚´ìš©ì„ ë°”ê¿”ì„œ ì‘ì„±**
- ì˜ˆì‹œ:
  * ì›ë³¸: "ê°±ë…„ê¸° ì¦ìƒ..." + í‚¤ì›Œë“œ: "ì ì‹¤ìœ ë°©ì™¸ê³¼"
    â†’ âŒ ê°±ë…„ê¸° ì–˜ê¸°ì— ìœ ë°©ì™¸ê³¼ ë¼ì›Œë„£ê¸° (ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
    â†’ âœ… ìœ ë°© ê±´ê°• ê²€ì§„, ìœ ë°©ì™¸ê³¼ ë°©ë¬¸ í›„ê¸°ë¡œ ì•„ì˜ˆ ìƒˆë¡œ ì‘ì„±

  * ì›ë³¸: "ê°±ë…„ê¸° ì¦ìƒ..." + í‚¤ì›Œë“œ: "ì—¬ì„±í—¤ì–´ë¼ì¸ ëª¨ë°œì´ì‹"
    â†’ âŒ ê°±ë…„ê¸°ì— ëª¨ë°œì´ì‹ ë¼ì›Œë„£ê¸° (ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
    â†’ âœ… í—¤ì–´ë¼ì¸ ê³ ë¯¼, ëª¨ë°œì´ì‹ ìƒë‹´ í›„ê¸°ë¡œ ìƒˆë¡œ ì‘ì„±

## ğŸ“ ì›ë³¸ì—ì„œ ìœ ì§€í•  ê²ƒ (í†¤&ë§¤ë„ˆë§Œ)
- ë§íˆ¬ì™€ ìŠ¤íƒ€ì¼ (ë°˜ë§/ì¡´ëŒ“ë§, êµ¬ì–´ì²´ ëŠë‚Œ)
- ì§ˆë¬¸í˜• êµ¬ì¡° (ìˆë‹¤ë©´)
- ê²½í—˜ë‹´ ê³µìœ  ìš”ì²­ ìŠ¤íƒ€ì¼
- ê³ ë¯¼ í† ë¡œí•˜ëŠ” ëŠë‚Œ
- ì •ë³´ ìš”ì²­ ë¬¸ì¥ (ì˜ˆ: "ì •ë³´ ê³µìœ  ì¢€ í•´ì£¼ì„¸ìš”")

## âœ… íšŒì‚¬ ê¸°ì¤€ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

### 1. ê¸€ììˆ˜: 300~900ì
- ê³µë°±/ì¤„ë°”ê¿ˆ ì œì™¸
- 300ì ë¯¸ë§Œì´ë©´ ë‚´ìš© ì¶”ê°€
- 900ì ì´ˆê³¼ë©´ ì¶•ì•½

### 2. ì²« ë¬¸ë‹¨ ê·œì¹™ (ì •í™•íˆ!)
- **í†µí‚¤ì›Œë“œ ì •í™•íˆ 2íšŒ** (1íšŒ âŒ, 3íšŒ âŒ)
- **í†µí‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(ì¤„) ì •í™•íˆ 2ê°œ**
- ì˜ˆì‹œ:
  ```
  {keyword}ì— ëŒ€í•´ ê¶ê¸ˆí•´ì„œ ê¸€ì„ ì˜¬ë¦½ë‹ˆë‹¤.  â† ì‹œì‘ 1
  {keyword} ì•Œì•„ë³´ë‹¤ê°€ ë„ˆë¬´ ë§‰ë§‰í•´ì„œìš”.        â† ì‹œì‘ 2
  ```

### 3. ë‚˜ë¨¸ì§€ ë¶€ë¶„ (ì²« ë¬¸ë‹¨ ì œì™¸)
- Dì—´ ëª©í‘œ: {target_whole_str}
- Eì—´ ëª©í‘œ: {target_pieces_str}
- ëª©í‘œ íšŸìˆ˜ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜

### 4. í‚¤ì›Œë“œ ì¹´ìš´íŒ… ê·œì¹™ âš ï¸âš ï¸âš ï¸ (ê·¹ë„ë¡œ ì¤‘ìš”!)
**í‚¤ì›Œë“œ ë’¤ì— ì¡°ì‚¬(ì„/ë¥¼/ê°€/ì´/ì—/ë„ ë“±)ê°€ ë¶™ìœ¼ë©´ ì¹´ìš´íŒ… ì•ˆ ë¨!**

âŒ **ì ˆëŒ€ ì´ë ‡ê²Œ ì“°ì§€ ë§ˆì„¸ìš”:**
- "{keyword}ë¥¼" â†’ ì¹´ìš´íŒ… X
- "{keyword}ì„" â†’ ì¹´ìš´íŒ… X
- "{keyword}ê°€" â†’ ì¹´ìš´íŒ… X
- "{keyword}ì´" â†’ ì¹´ìš´íŒ… X
- "{keyword}ì—" â†’ ì¹´ìš´íŒ… X (!!!íŠ¹íˆ ì£¼ì˜!!!)
- "{keyword}ë„" â†’ ì¹´ìš´íŒ… X

âœ… **ì´ë ‡ê²Œ ì¨ì•¼ ì¹´ìš´íŒ… ë¨:**
- "{keyword} ê´€ë ¨í•´ì„œ" â†’ ì¹´ìš´íŒ… O
- "{keyword} ë•Œë¬¸ì—" â†’ ì¹´ìš´íŒ… O
- "{keyword} ì•Œì•„ë³´ë‹¤ê°€" â†’ ì¹´ìš´íŒ… O
- "{keyword} ì •ë³´ë¥¼" â†’ ì¹´ìš´íŒ… O
- "{keyword}." (ë§ˆì¹¨í‘œ) â†’ ì¹´ìš´íŒ… O
- "{keyword}?" (ë¬¼ìŒí‘œ) â†’ ì¹´ìš´íŒ… O

**âš ï¸ ì ˆëŒ€ ì¡°ì‚¬ë¥¼ ì–µì§€ë¡œ ë„ìš°ì§€ ë§ˆì„¸ìš”!**
- âŒ "{keyword} ì„" (ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
- âœ… ë¬¸ì¥ì„ ë°”ê¿”ì„œ ì¡°ì‚¬ ì•ˆ ì“°ê¸°

### 5. ê¸ˆì¹™ì–´
- ê¸ˆì¹™ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ë°œê²¬ ì¦‰ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ êµì²´

### 6. ë¬¸ì²´ (ìì—°ìŠ¤ëŸ¬ì›€)
- ì‚¬ëŒì´ ì“´ ëŠë‚Œ ìœ ì§€
- ë„ˆë¬´ ì •ì œí•˜ê±°ë‚˜ ê´‘ê³ ê°™ì´ ì“°ì§€ ë§ ê²ƒ
- ì§„ì†”í•œ ê³ ë¯¼ í† ë¡œ ìŠ¤íƒ€ì¼
- ëŒ“ê¸€ ìœ ë„ ë¬¸ì¥ í¬í•¨

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ“¤ ì¶œë ¥ í˜•ì‹
**ìˆ˜ì •ëœ ì›ê³ ë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…, ì£¼ì„, ë¶„ì„ ì—†ì´ ì›ê³  í…ìŠ¤íŠ¸ë§Œ.
"""
        return prompt

    def rewrite_manuscript(self, manuscript: str, keyword: str,
                          target_whole_str: str, target_pieces_str: str,
                          target_subkeywords: int) -> Dict:
        """ì›ê³  ìë™ ìˆ˜ì •"""

        # 1. ë¶„ì„
        analysis = self.analyze_manuscript(manuscript, keyword, target_whole_str,
                                          target_pieces_str, target_subkeywords)

        print(f"\n{'=' * 100}")
        print(f"ì›ê³  ë¶„ì„ - í‚¤ì›Œë“œ: {keyword}")
        print(f"{'=' * 100}")
        print(f"ê¸€ììˆ˜: {analysis['chars']}ì (ëª©í‘œ: 300~900ì)")
        print(f"ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ (ëª©í‘œ: 2íšŒ)")
        print(f"í†µí‚¤ì›Œë“œ ë¬¸ì¥ ì‹œì‘: {analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ (ëª©í‘œ: 2ê°œ)")

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.create_rewrite_prompt(manuscript, keyword, analysis,
                                           target_whole_str, target_pieces_str)

        # 3. Geminië¡œ ìˆ˜ì •
        print(f"\nğŸ¤– Geminiê°€ ì›ê³ ë¥¼ ìˆ˜ì • ì¤‘...")
        try:
            response = self.model.generate_content(prompt)
            rewritten = response.text.strip()

            # 4. ìˆ˜ì • í›„ ì¬ë¶„ì„
            after_analysis = self.analyze_manuscript(rewritten, keyword, target_whole_str,
                                                    target_pieces_str, target_subkeywords)

            print(f"\nâœ… ìˆ˜ì • ì™„ë£Œ!")
            print(f"{'=' * 100}")
            print(f"ìˆ˜ì • í›„ ìƒíƒœ:")
            print(f"  ê¸€ììˆ˜: {after_analysis['chars']}ì")
            print(f"  ì²«ë¬¸ë‹¨ í†µí‚¤ì›Œë“œ: {after_analysis['ì²«ë¬¸ë‹¨_í†µí‚¤ì›Œë“œ']}íšŒ")
            print(f"  í†µí‚¤ì›Œë“œ ë¬¸ì¥ ì‹œì‘: {after_analysis['í†µí‚¤ì›Œë“œ_ë¬¸ì¥ì‹œì‘']}ê°œ")

            return {
                'success': True,
                'original': manuscript,
                'rewritten': rewritten,
                'before_analysis': analysis,
                'after_analysis': after_analysis
            }

        except Exception as e:
            print(f"âŒ ìˆ˜ì • ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'original': manuscript
            }


def test_rewriter():
    """í…ŒìŠ¤íŠ¸"""

    # API í‚¤ í™•ì¸
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    rewriter = AutoManuscriptRewriter()

    # í…ŒìŠ¤íŠ¸ ì›ê³ 
    test_manuscript = """ê°±ë…„ê¸°í™ì¡° ë•Œë¬¸ì— ì •ë§ ê³ ë¯¼ì´ ë§ìŠµë‹ˆë‹¤.
ì €ëŠ” 50ëŒ€ ì¤‘ë°˜ì¸ë° ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”.
ê°±ë…„ê¸°í™ì¡°ê°€ ì‹œì‘ëœ ì§€ 6ê°œì›”ì´ ë„˜ì—ˆëŠ”ë° ì¦ìƒì´ ì‹¬í•´ìš”.
ì–¼êµ´ì´ í™”ëˆê±°ë¦¬ê³  ì—´ì´ ì˜¬ë¼ìš”.
ë³‘ì›ì—ì„œ ì¹˜ë£Œë„ ë°›ì•„ë´¤ëŠ”ë° ë¶€ì‘ìš©ì´ ê±±ì •ë˜ë”ë¼ê³ ìš”.
íš¨ê³¼ê°€ ìˆëŠ” ë°©ë²• ì¢€ ì•Œë ¤ì£¼ì„¸ìš”."""

    keyword = "ê°±ë…„ê¸°í™ì¡°"
    target_whole = "ê°±ë…„ê¸°í™ì¡° : 0"
    target_pieces = "-"
    target_subkeywords = 5

    result = rewriter.rewrite_manuscript(test_manuscript, keyword, target_whole,
                                        target_pieces, target_subkeywords)

    if result['success']:
        print(f"\n\n{'=' * 100}")
        print("ìˆ˜ì •ëœ ì›ê³ :")
        print(f"{'=' * 100}")
        print(result['rewritten'])


if __name__ == '__main__':
    test_rewriter()
